---
title: "Fourth workshop module: Using Amazon Rekognition Custom Labels from R"
output: html_notebook
---

## Introduction

> **Info**
> 
> At the time of writing this article (Nov 2020), Amazon Rekognition Custom Labels is available in 4 regions
> us-east-1 (N. Virginia), us-east-2 (Ohio), us-west-2 (Oregon), and eu-west-1 (Ireland).
> Please make sure to update the `AWS_REGION` entry in the `.Renviron` file in case you configured another AWS region. 
>
> The service is currently also part of the AWS Free Tier which means you can get started for free:
> The service-specific Free Tier lasts 3 months and includes 10 free training hours per month and 4 free inference 
> hours per month.

You can use Rekogntion Custom Labels to train your own ML models that perform image classification (image level predictions) or object detection (object/bounding box level predictions).

The process of using Rekognition Custom Labels to train, evaluate, deploy and use both types of ML models is the same and consists of the following steps:

* Step 1: Create a S3 Custom Labels default bucket in your region
* Step 2: Create your project
* Step 3: Upload your dataset to S3
* Step 4: Create a Rekognition Custom Labels dataset
* Step 5: Train your model
* Step 6: Evaluate the training results
* Step 7: Deploy your model
* Step 8: Make real-time predictions for new data
* Step 9: Stop your model

The following image describes all the steps and their interrelations in detail. You don't need to understand everything now! Just use it as a reference when you like to organize several Rekognition Custom Labels projects later in your AWS account. 

Below we will create an image classification model for image level predictions of Game of Thrones characters. For this, we will follow the steps described above. Some of the steps are not supported by the Rekognition API. For those, we will use the Amazon Rekognition Custom Labels Console.  


## Before we get started ...

https://docs.aws.amazon.com/rekognition/latest/customlabels-dg/limits.html




## Load the necessary libraries 

```{r message=FALSE }
library(paws)
library(purrr)
library(readr)
library(tibble)
library(jsonlite)
library(magick)
```


## Step 1: Create S3 Custom Labels bucket

Creating the S3 Custom Labels bucket is an one-time step per region in which you like to use Amazon Rekognition Custom Labels which you don't need to repeat afterwards. 

In the AWS Console select **Amazon Rekognition** underneath services and then select **Use Custom Labels** in the left sidebar. Click on **Get started** in the middle of the Amazon Rekognition Custom Labels Console and then on **Create S3 bucket** to create your Rekognition Custom Labels default bucket in your region:

![](images/00_create_default_bucket.PNG)

You can safely ignore the prompt in the console to create your first Custom Labels project. We will do this in the next step via the API.

Next, we create an S3 client to retrieve the name of our S3 Rekognition Custom Labels default bucket which we will need later: 

```{r}
s3 <- s3()
region <- Sys.getenv("AWS_REGION")

custom_labels_bucket <- s3$list_buckets() %>% 
  .[["Buckets"]] %>% 
  map_chr("Name") %>% 
  keep(function(x) startsWith(x, paste0("custom-labels-console-", region)))

custom_labels_bucket
```

## Step 2: Create your project

The primary purpose of Rekognition Custom Labels projects is to manage the lifecycle of your ML models. A trained model always belongs to one project. A project just serves as an umbrella under which you train, deploy and manage one or more ML models. 


Within Amazon Rekognition Custom Labels, you use projects to manage the models that you create. A project manages the input images and labels, datasets, model training, model evaluation, and running the model

We will create a Rekognition client and create our first Custom Labels project:

```{r}
rek <- rekognition()

project_arn <- rek$create_project("got_image_classification")
```

`create_project()` returns the project's Amazon Resource Name (ARN). We will store it in a separate variable which we will need later when defining the training job for our image classification model. 


Alternatively, you can also use the following code snipped to retrieve the entire list of your Rekognition Custom Labels projects and to select the project of your choice:

```{r eval=FALSE}
rek$describe_projects() %>% 
  pluck("ProjectDescriptions") %>% 
  map_chr("ProjectArn")
```


## Step 3: Upload your dataset


Now it is time to upload the image dataset to our S3 Custom Labels default bucket that we will use to train our Game of Thrones image classification model. But wait! We don't have these images yet. 

We will use the [Game of thrones character classification dataset](https://www.kaggle.com/kushagrakinjawadekar/game-of-thrones-character-classification) from Kaggle. Just press the **Download (115MB)** button on the page to download the dataset to your machine. Once the download is complete, please unzip *archive.zip*. 

Now we will create two new folders in our S3 Custom Labels default bucket. 

```{r}
s3$put_object(Bucket = custom_labels_bucket, Key = "/assets/got_characters_kaggle/", Body = "")

```

Underneath `/assets` we will organize our raw data sets and the outputs of our training runs

we will store all raw data sets we will use in our Custom Labels projects in separate folders. We will now upload.




s3 = boto3.client('s3')
bucket_name = "aniketbucketpython"
directory_name = "aniket/bucket/python" #it's name of your folders
s3.put_object(Bucket=bucket_name, Key=(directory_name+'/'))


Next, we navigate to the Amazon S3 Console and create 




## Step 4: Create a Rekognition Custom Labels dataset

Now we need to register the data set we uploaded to the S3 Custom Labels bucket in Rekognition Custom Labels. 
This step is necessary so that we can create a project/training job in Rekognition Custom Labels that will reference the registered data set. 

We do this to create the manifest file which we need to reference in the next step when starting a training job. 
The manifest file includes the correct labels of our images. 


This step is not yet supported via the official API and thus nor via paws. 

Rek CL datasets cannot be deleted. It seems you need to delete the underlying referenced S3 bucket content to get rid of the dataset in the Rek console. 
solution: delete datasets/ and index/ folder in the S3 Custom Labels folder which will automatically remove dataset in Rek console. 


## Step 7: Deploy your model

```{r}

model_arn <- training_results %>% 
  pluck("ProjectVersionDescriptions", 1, "ProjectVersionArn")


rek$start_project_version(ProjectVersionArn = model_arn, 
                          MinInferenceUnits = 1 )

```

### dec12

```{r}
project_arns <- rek$describe_projects() %>% 
  pluck("ProjectDescriptions") %>% 
  map_chr("ProjectArn") 

swoosh_project <- project_arns[grepl("swoosh_detection3", project_arns)]

#rek$describe_project_versions(swoosh_project)

model_arn <- rek$describe_project_versions(swoosch_project) %>% 
  pluck("ProjectVersionDescriptions" , 1, "ProjectVersionArn")
  
```

```{r}
rek$start_project_version(ProjectVersionArn = model_arn, MinInferenceUnits = 1)
```

```{r}
#rek$describe_project_versions(project_arn, version_name) %>% 
#  pluck("ProjectVersionDescriptions", 1, "Status")

rek$describe_project_versions(swoosh_project, "swoosh_detection3.2020-11-29T20.53.55") %>% 
  pluck("ProjectVersionDescriptions", 1, "Status")
```
## Step 8: Make real-time predictions for new data

```{r}

file_names <- list.files("./images/Inf2/")

file <- paste0("./images/Inf2/", file_names[1])

image <- read_file_raw(file)

resp <- rek$detect_custom_labels(ProjectVersionArn = model_arn,
                                 Image = list(
                                   Bytes = image
                                 )
)

# Parse the result
names <- resp$CustomLabels %>% 
  map_chr("Name")
confidence <- resp$CustomLabels %>% 
  map_dbl("Confidence")

tibble(names, confidence)
```


```{r fig.align="center", out.width = "60%"}

# Convert raw image into a magick object
magick_image <- image_read(file)
image_attr <- image_info(magick_image)

# Extract bounding box information of detected object(s) from the response
bounding_boxes <- resp$CustomLabels

bb <- map(bounding_boxes, function(x) {
  bounding_box <- x[["Geometry"]][["BoundingBox"]]
  width <- bounding_box$Width * image_attr$width 
  height <- bounding_box$Height * image_attr$height
  left <- bounding_box$Left * image_attr$width 
  top <- bounding_box$Top * image_attr$height
  cords <- c(width = width, height = height, left = left, top = top)
  cords
})

# Calculate bounding box properties

bb <- bind_rows(bb)


# Add bounding box to suspects image / rect can accept vector 
image <- magick_image %>% 
  image_draw()
rect(bb$left, bb$top, bb$left + bb$width, bb$top + bb$height, border = "red", lty = "dashed", lwd = 15)
dev.off()
```

```{r fig.align="center", out.width = "60%"}

# Convert raw image into a magick object
magick_image <- image_read(file)

# Extract bounding box information of detected object(s) from the response
bounding_box_properties <- resp$CustomLabels[[1]]$Geometry$BoundingBox

# Calculate bounding box properties
width <- bounding_box_properties$Width * image_info(magick_image)$width 
height <- bounding_box_properties$Height * image_info(magick_image)$height
left <- bounding_box_properties$Left * image_info(magick_image)$width 
top <- bounding_box_properties$Top * image_info(magick_image)$height

# Add bounding box to suspects image
image <- magick_image %>% 
  image_draw()
rect(left, top, left + width, top + height, border = "red", lty = "dashed", lwd = 5)
dev.off()
```


## Step 9: Stop your model

```{r}
resp <- rek$stop_project_version(model_arn)
```



## Summary 

```{r}

```



